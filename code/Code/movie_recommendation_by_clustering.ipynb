{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터링 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf=pd.read_csv('./dataset/movies04293.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=pd.read_csv('./dataset/movie_plot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class movie_recommendation_cluster:\n",
    "    def __init__(self, **kargs):\n",
    "        self.topn = kargs.get('topn', 10)\n",
    "        self.df = kargs.get('data', pd.read_csv('./dataset/movie_plot.csv'))\n",
    "        self.a, self.b, self.c = kargs.get('a',0.8), kargs.get('b',0.1), kargs.get('c',0.1)\n",
    "        self.n_clusters = kargs.get('n_clusters',30)# kmeans\n",
    "        self.n_components = kargs.get('n_components', 500)# svd\n",
    "        self.vote_thres = kargs.get('vote_thres',100)# vote_count\n",
    "        self.verbose = kargs.get('verbose', 1)\n",
    "        self.re_cluster = kargs.get('re_cluster', 1)# kmeans\n",
    "        self.batch_size = kargs.get('batch_size', 2000)\n",
    "        self.max_iter = kargs.get('max_iter', 500)\n",
    "        \n",
    "        self.cvec = CountVectorizer(min_df=0, ngram_range=(1,2))\n",
    "        self.stops = []\n",
    "        with open('./stopwords/total_stopwords', encoding='utf-8') as f:\n",
    "            self.stops.append(f.readline()[:-2])\n",
    "        \n",
    "        if self.verbose == 1:\n",
    "            print('-'*35)\n",
    "            print('# Parameters')\n",
    "            print('      a, b, c        : {0}, {1}, {2}'.format(self.a, self.b, self.c))\n",
    "            print('vote count threshold :', self.vote_thres)\n",
    "            print(\"n_components of SVD  :\", self.n_components)\n",
    "            print(\"n_clusters of KMeans :\", self.n_clusters)\n",
    "            print('batch_size of Kmeans :', self.batch_size)\n",
    "            print('max_iter of Kmeans   :', self.max_iter)\n",
    "            print('weighted_sum = dist_scaled*{0}(a) + genre_scaled*{1}(b) + wvote_scaled*{2}(c)'.format(self.a, self.b, self.c))\n",
    "            print('-'*35)\n",
    "    \n",
    "    def search_title(self, title_name):\n",
    "        return self.df[self.df['title'].str.contains(title_name)].title\n",
    "    \n",
    "    def genre_sim_sorted(self, title_idx):\n",
    "        genre_literal = self.df['genre'].apply(lambda x: x.replace('|',' '))\n",
    "        genre = self.cvec.fit_transform(genre_literal)\n",
    "        genre_sim = cosine_similarity(genre,genre)\n",
    "        \n",
    "        return np.array([(idx,sim) for idx,sim in enumerate(genre_sim[title_idx])])\n",
    "    \n",
    "    def raw_to_tfidf(self, data_preprocess):\n",
    "        tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,3),stop_words=self.stops,\n",
    "                                     min_df=3, max_df=0.95, max_features=10000)\n",
    "        return tfidf.fit_transform(data_preprocess)\n",
    "    def tfidf_to_svd(self, data_tfidf):\n",
    "        svd = TruncatedSVD(n_components=self.n_components, n_iter=10)\n",
    "        return svd.fit_transform(data_tfidf)\n",
    "    \n",
    "    def similar_cluster_movies(self, title_idx):\n",
    "        do_cluster, loop_cnt = True, 0\n",
    "        \n",
    "        # data preprocessing\n",
    "        data_tfidf = self.raw_to_tfidf(list(map(str, self.df['plot_preprocessed_kkma'].values)))\n",
    "        data_svd = self.tfidf_to_svd(data_tfidf)\n",
    "        \n",
    "        # K-means clustering\n",
    "        print('Clustering...')\n",
    "        while do_cluster:\n",
    "            kmeans = MiniBatchKMeans(n_clusters=self.n_clusters, batch_size=self.batch_size,\n",
    "                                     max_iter=self.max_iter, verbose=0 ,n_init=3)\n",
    "\n",
    "            vote_over_thres_idx = self.df[self.df['vote_count'] > self.vote_thres].index\n",
    "            data_svd_idx = np.array([(idx,val) for idx,val in zip(self.df.index,data_svd)])\n",
    "            data_svd_to_km = [val for idx,val in data_svd_idx if idx in vote_over_thres_idx]\n",
    "            data_svd_dict = dict([(idx,val) for idx,val in filter(lambda x: x[0] in vote_over_thres_idx, data_svd_idx)])\n",
    "            \n",
    "            # (optional)avoid biggest cluster\n",
    "            km = kmeans.fit(data_svd_to_km)\n",
    "            km_dict = dict([(df_idx,label_) for df_idx,label_ in zip(vote_over_thres_idx,km.labels_)])\n",
    "            km_cluster = list(filter(lambda x: km_dict.get(x) == km_dict.get(title_idx), km_dict.keys()))\n",
    "\n",
    "            clusters = [0]*self.n_clusters\n",
    "            for label_ in km.labels_:\n",
    "                clusters[label_] += 1\n",
    "\n",
    "            clusters_idx = np.array(clusters).argsort()\n",
    "            bad_clusters = clusters_idx[-3:]\n",
    "            \n",
    "            if self.re_cluster:            \n",
    "                if km_dict.get(title_idx) not in bad_clusters:\n",
    "                    do_cluster=False\n",
    "                elif loop_cnt >= 20:\n",
    "                    print('Loop count exceeded')\n",
    "                    do_cluster=False\n",
    "                else:\n",
    "                    del kmeans\n",
    "                    loop_cnt += 1\n",
    "                    print('Re-clustering...(%d)'%(loop_cnt))\n",
    "                    \n",
    "            else:\n",
    "                do_cluster = False\n",
    "\n",
    "        if self.verbose == 1:\n",
    "            print('-'*35)\n",
    "            print('# K-means clustering distribution')\n",
    "            for i,size in enumerate(clusters):\n",
    "                postfix = '<==' if i == km_dict.get(title_idx) else ''\n",
    "                print('cluster #%3d : %4d items %s'%(i,size,postfix))\n",
    "            print('-'*35)\n",
    "\n",
    "        closest = []\n",
    "        for i in km_cluster:\n",
    "            if i != title_idx:\n",
    "                closest.append((i,euclidean(data_svd_dict.get(title_idx), data_svd_dict.get(i))))\n",
    "\n",
    "        return np.array(closest), self.df.loc[np.array(sorted(closest, key=lambda x: x[1]))[:,0]]\n",
    "\n",
    "    def result_by_weights(self, dataf):\n",
    "        dataf['weighted_sum'] = dataf['dist_scaled']*self.a + dataf['genre_scaled']*self.b + dataf['wvote_scaled']*self.c\n",
    "        \n",
    "        return dataf.sort_values('weighted_sum', ascending=False)\n",
    "\n",
    "            \n",
    "    def getMovies(self, title):\n",
    "        # no title result\n",
    "        try: title_idx = self.df[self.df['title']== title].index.values[0]\n",
    "        except:\n",
    "            raise ValueError('There is no such title name. Search with \"search_title\" function')\n",
    "        \n",
    "        # get movies in same cluster\n",
    "        dist, result = self.similar_cluster_movies(title_idx)\n",
    "        \n",
    "        # merge with distance\n",
    "        result = pd.merge(result, pd.Series(dist[:,1], name='dist'), left_on=result.index, right_on=dist[:,0])\n",
    "        result.rename(columns={'key_0':'idx'}, inplace=True)\n",
    "        \n",
    "        # IMDB's weighted_vote\n",
    "        def weighted_vote_average(record):\n",
    "            v, r = record['vote_count'], record['rating']\n",
    "            return (v/(v+m))*r + (m/(m+v))*c\n",
    "        c = result['rating'].mean()\n",
    "        m = result['vote_count'].quantile(.6)\n",
    "        result['weighted_vote'] = result.apply(weighted_vote_average,axis=1)\n",
    "        \n",
    "        # merge with genre\n",
    "        genre_sim = self.genre_sim_sorted(title_idx)\n",
    "        result_with_genre = pd.merge(result, pd.Series(genre_sim[:,1], name='genre_sim'), left_on=result.idx, right_on=genre_sim[:,0],)\n",
    "        \n",
    "        # minmax scale\n",
    "        result_with_genre['wvote_scaled'] = MinMaxScaler().fit_transform(result_with_genre['weighted_vote'].values.reshape(-1,1))\n",
    "        result_with_genre['genre_scaled'] = MinMaxScaler().fit_transform(result_with_genre['genre_sim'].values.reshape(-1,1))\n",
    "        result_with_genre['dist_scaled'] = MinMaxScaler().fit_transform(result_with_genre['dist'].max() - result_with_genre['dist'].values.reshape(-1,1))\n",
    "        \n",
    "        # (optional)remove data with 0 genre score\n",
    "        no_genre_score_idx = result_with_genre[result_with_genre['genre_sim'] == 0].index\n",
    "        result_with_genre.drop(no_genre_score_idx, inplace=True)\n",
    "        \n",
    "        result_with_genre = self.result_by_weights(result_with_genre)\n",
    "        return result_with_genre.head(self.topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "# Parameters\n",
      "      a, b, c        : 0.8, 0.1, 0.1\n",
      "vote count threshold : 100\n",
      "n_components of SVD  : 500\n",
      "n_clusters of KMeans : 30\n",
      "batch_size of Kmeans : 2000\n",
      "max_iter of Kmeans   : 500\n",
      "weighted_sum = dist_scaled*0.8(a) + genre_scaled*0.1(b) + wvote_scaled*0.1(c)\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "recom = movie_recommendation_cluster(re_cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering...\n",
      "Re-clustering...(1)\n",
      "Re-clustering...(2)\n",
      "Re-clustering...(3)\n",
      "Re-clustering...(4)\n",
      "Re-clustering...(5)\n",
      "Re-clustering...(6)\n",
      "Re-clustering...(7)\n",
      "Re-clustering...(8)\n",
      "-----------------------------------\n",
      "# K-means clustering distribution\n",
      "cluster #  0 :  291 items \n",
      "cluster #  1 : 1111 items \n",
      "cluster #  2 :  863 items \n",
      "cluster #  3 :   14 items \n",
      "cluster #  4 :   70 items \n",
      "cluster #  5 : 2017 items \n",
      "cluster #  6 :    9 items \n",
      "cluster #  7 :    3 items \n",
      "cluster #  8 :   42 items \n",
      "cluster #  9 :    2 items \n",
      "cluster # 10 :   89 items \n",
      "cluster # 11 :    5 items \n",
      "cluster # 12 :  147 items \n",
      "cluster # 13 :  196 items \n",
      "cluster # 14 :   11 items \n",
      "cluster # 15 :  355 items \n",
      "cluster # 16 :    5 items \n",
      "cluster # 17 :  858 items <==\n",
      "cluster # 18 :   19 items \n",
      "cluster # 19 :  176 items \n",
      "cluster # 20 :    4 items \n",
      "cluster # 21 :  358 items \n",
      "cluster # 22 :    0 items \n",
      "cluster # 23 :  112 items \n",
      "cluster # 24 :    1 items \n",
      "cluster # 25 :  282 items \n",
      "cluster # 26 :    4 items \n",
      "cluster # 27 :   49 items \n",
      "cluster # 28 :    3 items \n",
      "cluster # 29 :    3 items \n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = recom.getMovies('박물관이 살아있다 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_sum</th>\n",
       "      <th>title</th>\n",
       "      <th>dist_scaled</th>\n",
       "      <th>genre_scaled</th>\n",
       "      <th>wvote_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.916877</td>\n",
       "      <td>찰리와 초콜릿 공장</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.835711</td>\n",
       "      <td>0.869128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901964</td>\n",
       "      <td>극장판 소드 아트 온라인 -오디널 스케일-</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164804</td>\n",
       "      <td>0.854839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.853929</td>\n",
       "      <td>신밧드 - 7대양의 전설</td>\n",
       "      <td>0.923292</td>\n",
       "      <td>0.417855</td>\n",
       "      <td>0.735095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.851375</td>\n",
       "      <td>리오</td>\n",
       "      <td>0.874230</td>\n",
       "      <td>0.696426</td>\n",
       "      <td>0.823484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.826878</td>\n",
       "      <td>판타스틱 Mr. 폭스</td>\n",
       "      <td>0.851948</td>\n",
       "      <td>0.696426</td>\n",
       "      <td>0.756766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.821322</td>\n",
       "      <td>미이라 2</td>\n",
       "      <td>0.881091</td>\n",
       "      <td>0.368514</td>\n",
       "      <td>0.795977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.813848</td>\n",
       "      <td>배틀필드</td>\n",
       "      <td>0.906127</td>\n",
       "      <td>0.212762</td>\n",
       "      <td>0.676707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.802074</td>\n",
       "      <td>아이스 에이지 2</td>\n",
       "      <td>0.841124</td>\n",
       "      <td>0.557141</td>\n",
       "      <td>0.734611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.789119</td>\n",
       "      <td>아이언맨 2</td>\n",
       "      <td>0.860691</td>\n",
       "      <td>0.329609</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.785607</td>\n",
       "      <td>마고리엄의 장난감 백화점</td>\n",
       "      <td>0.837918</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.493501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    weighted_sum                    title  dist_scaled  genre_scaled  \\\n",
       "2       0.916877               찰리와 초콜릿 공장     0.932991      0.835711   \n",
       "0       0.901964  극장판 소드 아트 온라인 -오디널 스케일-     1.000000      0.164804   \n",
       "3       0.853929            신밧드 - 7대양의 전설     0.923292      0.417855   \n",
       "7       0.851375                       리오     0.874230      0.696426   \n",
       "11      0.826878              판타스틱 Mr. 폭스     0.851948      0.696426   \n",
       "6       0.821322                    미이라 2     0.881091      0.368514   \n",
       "4       0.813848                     배틀필드     0.906127      0.212762   \n",
       "16      0.802074                아이스 에이지 2     0.841124      0.557141   \n",
       "10      0.789119                   아이언맨 2     0.860691      0.329609   \n",
       "18      0.785607            마고리엄의 장난감 백화점     0.837918      0.659218   \n",
       "\n",
       "    wvote_scaled  \n",
       "2       0.869128  \n",
       "0       0.854839  \n",
       "3       0.735095  \n",
       "7       0.823484  \n",
       "11      0.756766  \n",
       "6       0.795977  \n",
       "4       0.676707  \n",
       "16      0.734611  \n",
       "10      0.676056  \n",
       "18      0.493501  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[['weighted_sum','title','dist_scaled','genre_scaled','wvote_scaled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
